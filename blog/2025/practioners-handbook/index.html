<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Prompt Practitioner's Handbook - Heuristics for Better Industry Research | Danial Amin </title> <meta name="author" content="Danial Amin"> <meta name="description" content="Effective LLM prompting for industry research isn't about perfect instructions—it's about applying battle-tested heuristics that consistently produce actionable insights. These practical principles transform generic AI interactions into focused research partnerships."> <meta name="keywords" content="human-computer interaction, generative ai, personas, user representation, fairness"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?05bb9ffd5c923af1a6eccf0d57836de3"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://danial-amin.github.io/blog/2025/practioners-handbook/"> <script src="/assets/js/theme.js?cef5f310457b5b065775c7a31be91f90"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.key-insight{background:linear-gradient(135deg,#28a745 0%,#20c997 100%);color:white;padding:1.5rem;border-radius:.5rem;margin:2rem 0}.heuristic-box{background:#d4edda;border-left:4px solid #28a745;padding:1rem;margin:2rem 0;border-radius:.25rem}.prompt-example{background:#f8f9fa;border:1px solid #dee2e6;padding:1rem;margin:1rem 0;border-radius:.25rem;font-family:monospace;font-size:.9em}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "The Prompt Practitioner's Handbook - Heuristics for Better Industry Research",
            "description": "Effective LLM prompting for industry research isn't about perfect instructions—it's about applying battle-tested heuristics that consistently produce actionable insights. These practical principles transform generic AI interactions into focused research partnerships.",
            "published": "July 21, 2025",
            "authors": [
              
              {
                "author": "Danial Amin",
                "authorURL": "https://linkedin.com/in/danial-amin",
                "affiliations": [
                  {
                    "name": "Samsung Design Innovation Center, France",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Danial</span> Amin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>The Prompt Practitioner's Handbook - Heuristics for Better Industry Research</h1> <p>Effective LLM prompting for industry research isn't about perfect instructions—it's about applying battle-tested heuristics that consistently produce actionable insights. These practical principles transform generic AI interactions into focused research partnerships.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#the-specificity-principle">The Specificity Principle</a> </div> <div> <a href="#the-constraint-framework">The Constraint Framework</a> </div> <div> <a href="#the-evidence-demand">The Evidence Demand</a> </div> <div> <a href="#the-iteration-protocol">The Iteration Protocol</a> </div> </nav> </d-contents> <p>After years of crafting prompts for industry reports across technology, finance, and engineering sectors, a pattern emerges: <strong>the difference between mediocre and exceptional LLM research output isn’t sophisticated prompt engineering. Rather, it’s consistently applying simple heuristics that most people ignore.</strong></p> <p>Great prompting for industry research follows predictable principles. While each project has unique requirements, the underlying heuristics remain constant. These aren’t abstract theories but practical rules distilled from thousands of research interactions that consistently separate actionable insights from generic AI responses.</p> <p>The best industry researchers using LLMs don’t rely on prompt templates or complex frameworks. They internalize core heuristics that guide every interaction, ensuring that each prompt moves them closer to meaningful business intelligence rather than impressive-sounding fluff.</p> <div class="key-insight"> <strong>Core Truth:</strong> Effective research prompting is about constraint, not creativity. The best prompts severely limit what the LLM can say, forcing it to produce precise, evidence-backed insights rather than expansive generalities. </div> <h2 id="the-specificity-principle">The Specificity Principle</h2> <p>Generic prompts produce generic research. The most common mistake in industry research is asking LLMs for broad analysis when specific questions yield actionable answers.</p> <p><strong>Instead of:</strong> “Analyze the competitive landscape in renewable energy.”<br> <strong>Try:</strong> “Identify the three companies that gained the most market share in utility-scale solar installations in the US between 2022-2024, and explain their specific competitive advantages.”</p> <p>The specificity principle operates through three mechanisms:</p> <p><strong>Narrow Scope</strong>: Limit analysis to specific timeframes, geographies, or market segments<br> <strong>Precise Metrics</strong>: Ask for exact numbers, percentages, or rankings rather than general trends<br> <strong>Concrete Examples</strong>: Demand specific companies, products, or case studies rather than abstract categories</p> <div class="heuristic-box"> <strong>Heuristic #1:</strong> If your prompt could apply to any industry or time period, it's too generic. Good research prompts contain at least three specific constraints that narrow the scope to actionable intelligence. </div> <h3 id="the-context-sandwich-method">The Context Sandwich Method</h3> <p>Effective research prompts sandwich the core question between relevant context and output constraints:</p> <div class="prompt-example"> Context: "The pharmaceutical industry is facing increased pressure from generic competition and regulatory scrutiny on drug pricing." Core Question: "What are the top three strategic responses large pharma companies have implemented in the past 18 months to maintain profitability?" Output Constraint: "For each strategy, provide: the specific companies using it, measurable outcomes where available, and implementation challenges they've faced." </div> <p>This structure ensures the LLM understands the business context while preventing rambling responses that lack specificity.</p> <h2 id="the-constraint-framework">The Constraint Framework</h2> <p>Constraints aren’t limitations—they’re focusing mechanisms that force LLMs to prioritize quality over quantity. The most effective research prompts impose multiple constraints that guide the response toward actionable insights.</p> <h3 id="the-three-layer-constraint-system">The Three-Layer Constraint System</h3> <p><strong>Format Constraints</strong>: Specify exactly how you want information structured</p> <ul> <li>“Present findings as a ranked list with brief justifications”</li> <li>“Organize by geographic region with subsections for market drivers”</li> <li>“Use bullet points with quantified impacts where possible”</li> </ul> <p><strong>Evidence Constraints</strong>: Demand specific types of supporting information</p> <ul> <li>“Cite specific financial results or growth metrics”</li> <li>“Reference recent M&amp;A activity or partnerships”</li> <li>“Include regulatory changes or policy impacts”</li> </ul> <p><strong>Scope Constraints</strong>: Define clear boundaries for the analysis</p> <ul> <li>“Focus only on public companies with &gt;$1B revenue”</li> <li>“Limit to developments in the past 12 months”</li> <li>“Exclude early-stage startups and private companies”</li> </ul> <div class="heuristic-box"> <strong>Heuristic #2:</strong> The best research prompts feel restrictive. If your prompt gives the LLM too much freedom, you'll get creative writing instead of business intelligence. </div> <h3 id="the-exclusion-technique">The Exclusion Technique</h3> <p>Explicitly stating what you don’t want often produces better results than only stating what you do want:</p> <div class="prompt-example"> "Analyze supply chain disruptions in semiconductor manufacturing. Do NOT include: general COVID-19 impacts, theoretical future scenarios, or companies with &lt;$100M revenue. DO focus on: specific bottlenecks, company-level responses, and measurable timeline impacts." </div> <p>This prevents LLMs from defaulting to commonly discussed but less relevant information.</p> <h2 id="the-evidence-demand">The Evidence Demand</h2> <p>Industry research requires evidence-backed conclusions, not plausible-sounding speculation. The evidence demand principle ensures every claim can be traced to specific sources or verifiable information.</p> <h3 id="the-according-to-requirement">The “According to” Requirement</h3> <p>Force the LLM to attribute claims to specific sources:</p> <p><strong>Weak</strong>: “The SaaS market is experiencing rapid growth.” <strong>Strong</strong>: “According to [specific report/data], SaaS revenue grew X% in [timeframe], driven by [specific factors].”</p> <div class="prompt-example"> "Identify emerging trends in fintech adoption among small businesses. For each trend, specify: the data source, sample size or methodology, timeframe of the study, and which specific business segments show strongest adoption." </div> <h3 id="the-quantification-demand">The Quantification Demand</h3> <p>Whenever possible, require numerical evidence:</p> <ul> <li>Market size figures with growth rates</li> <li>Adoption percentages with timelines</li> <li>Revenue impacts with year-over-year comparisons</li> <li>User base numbers with geographic breakdowns</li> </ul> <div class="heuristic-box"> <strong>Heuristic #3:</strong> If the LLM can't provide numbers, names, or dates to support a claim, the claim probably isn't valuable for industry research. Demand specificity at every assertion. </div> <h3 id="the-source-separation-technique">The Source Separation Technique</h3> <p>Ask the LLM to distinguish between different types of evidence:</p> <div class="prompt-example"> "Separate your analysis into: (1) Data from industry reports and surveys, (2) Information from company financial filings, (3) Insights from executive interviews or statements, (4) Analysis from consulting firm research. Label each section clearly." </div> <p>This helps evaluate the reliability and relevance of different information sources.</p> <h2 id="the-iteration-protocol">The Iteration Protocol</h2> <p>Great industry research emerges through iterative refinement, not single perfect prompts. The iteration protocol treats each LLM response as a foundation for deeper investigation rather than a final answer.</p> <h3 id="the-drill-down-strategy">The Drill-Down Strategy</h3> <p>Start broad, then systematically narrow focus based on initial findings:</p> <p><strong>Round 1</strong>: “What are the major challenges facing electric vehicle manufacturers?”<br> <strong>Round 2</strong>: “You mentioned battery supply constraints. Which specific materials are most problematic and why?”<br> <strong>Round 3</strong>: “For lithium shortages specifically, which companies have developed alternative sourcing strategies?”</p> <h3 id="the-contradiction-check">The Contradiction Check</h3> <p>Actively test the reliability of LLM outputs by requesting contrary evidence:</p> <div class="prompt-example"> "You identified three growth drivers for cloud adoption. Now provide three factors that might slow or reverse this trend. Which evidence is stronger—the growth drivers or the limiting factors?" </div> <h3 id="the-cross-sector-validation">The Cross-Sector Validation</h3> <p>Verify insights by examining similar patterns in adjacent industries:</p> <div class="prompt-example"> "You've identified subscription fatigue in streaming services. Do similar patterns exist in SaaS, news media, or fitness apps? What does this suggest about the sustainability of subscription models generally?" </div> <div class="heuristic-box"> <strong>Heuristic #4:</strong> Never accept the first response as complete. The best insights emerge when you push the LLM to defend, refine, or contradict its initial analysis. </div> <h2 id="implementation-strategy">Implementation Strategy</h2> <p>Applying these heuristics requires systematic practice rather than occasional use. The most effective approach involves developing standard question templates that embed these principles:</p> <p><strong>For Market Analysis</strong>: “In [specific market segment] during [timeframe], which [number] companies achieved [specific metric], what [measurable strategies] did they use, and what [quantified outcomes] resulted?”</p> <p><strong>For Competitive Intelligence</strong>: “Among [defined competitor set] in [geographic/product scope], what [specific competitive moves] occurred in [timeframe], with what [measurable impacts] on [specific metrics]?”</p> <p><strong>For Trend Analysis</strong>: “What evidence from [source types] indicates [specific trend] is [strengthening/weakening] in [market segment] during [timeframe], and which [specific indicators] provide the strongest signal?”</p> <p>The goal isn’t perfect prompts but consistent application of focusing heuristics that transform generic LLM capabilities into sharp research tools. These principles work because they align with how business decisions are actually made—based on specific, evidence-backed insights rather than general observations.</p> <hr> <p><strong>The Bottom Line:</strong> Effective LLM research prompting is a discipline, not an art. Master these four heuristics—specificity, constraints, evidence demands, and iteration—and transform your industry research from impressive-sounding summaries into actionable business intelligence.</p> <p><strong>AI Attribution</strong>: This article was written with the assistance of Claude, an AI assistant created by Anthropic, demonstrating the prompting principles it advocates.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2025-07-21-practioners-handbook.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'damin-acad/damin-acad.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Danial Amin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Content by <a href="https://danial-amin.github.io/" target="_blank">Danial Amin</a>. Last updated: October 18, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>